{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e9833a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Python3v6/lib/python3.6/site-packages/ipykernel_launcher.py:106: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "PREDICTOR_PATH = \"shape_predictor_68_face_landmarks.dat\"\n",
    "bg_path1 = \"./bg_im/man_R\" #背景照片(./bg_im/ .jpeg)\n",
    "bg_path2 = \"./bg_im/man_L\" #背景照片(./bg_im/ .jpeg)\n",
    "female_path = \"./input_im/female/jennie1.jpeg\" #新娘照片\n",
    "male_path = \"./input_im/male/kor2.jpeg\" #新郎照片(./input_im/male/zy2.jpeg)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(PREDICTOR_PATH)\n",
    "\n",
    "\n",
    "f_im_or = cv2.imread(female_path) #新娘照片\n",
    "m_im_or = cv2.imread(male_path) #新郎照片\n",
    "\n",
    "def read_bg(bg_path):\n",
    "    bg_or_list = []\n",
    "    for filename in os.listdir(bg_path):\n",
    "        bg_or_list.append(cv2.imread(bg_path+\"/\"+filename))\n",
    "    return bg_or_list\n",
    "\n",
    "bg_or_list1 = read_bg(bg_path1)\n",
    "bg_or_list2 = read_bg(bg_path2)\n",
    "\n",
    "    \n",
    "def cut(im):\n",
    "        cut = []\n",
    "        left = []\n",
    "        faces = detector(im, 1)\n",
    "        for face in faces:\n",
    "            x1 = face.left()\n",
    "            y1 = face.top()\n",
    "            x2 = face.right()\n",
    "            y2 = face.bottom()\n",
    "            img_cap = im[y1-50:y2+50, x1-50:x2+50]\n",
    "            cut.append(img_cap)\n",
    "            left.append(x1)\n",
    "        return cut , left , img_cap    \n",
    "    \n",
    "#提取面部標誌\n",
    "def get_landmarks(im):\n",
    "    rects = detector(im, 1)\n",
    "\n",
    "    if len(rects) > 2:\n",
    "        raise TooManyFaces\n",
    "    if len(rects) == 0:\n",
    "        raise NoFaces\n",
    "\n",
    "    return np.matrix([[p.x, p.y] for p in predictor(im, rects[0]).parts()])\n",
    "\n",
    "\n",
    "def transformation_from_points(points1, points2):  #points1=bg, points2=input\n",
    "    points1 = points1.astype(np.float64) #將輸入矩陣轉換為浮點型\n",
    "    points2 = points2.astype(np.float64)\n",
    "\n",
    "    c1 = np.mean(points1, axis=0) \n",
    "    c2 = np.mean(points2, axis=0)\n",
    "    points1 -= c1  #將每一個點集減去它的矩心\n",
    "    points2 -= c2\n",
    "\n",
    "    s1 = np.std(points1)\n",
    "    s2 = np.std(points2)\n",
    "    points1 /= s1  #將每一個點集除以它的標準偏差。這消除了縮放偏差\n",
    "    points2 /= s2\n",
    "\n",
    "    #奇異值分解（singular value decomposition）計算旋轉部分\n",
    "    U, S, Vt = np.linalg.svd(points1.T * points2)\n",
    "    R = (U * Vt).T\n",
    "\n",
    "    #將整個變換過程以仿射變換矩陣形式返回\n",
    "    return np.vstack([np.hstack(((s2 / s1) * R,\n",
    "                                      c2.T - (s2 / s1) * R * c1.T)),\n",
    "                        np.matrix([0., 0., 1.])]), R\n",
    "\n",
    "\n",
    "#將第二個圖片對映到第一個圖片上\n",
    "def warp_im(im, M, dshape):\n",
    "    output_im = np.zeros(dshape, dtype=im.dtype)\n",
    "    cv2.warpAffine(im,\n",
    "                  M[:2],\n",
    "                  (dshape[1], dshape[0]),\n",
    "                  dst=output_im,\n",
    "                  borderMode=cv2.BORDER_TRANSPARENT,\n",
    "                  flags=cv2.WARP_INVERSE_MAP)\n",
    "    return output_im\n",
    "\n",
    "#修正膚色和光線，改變圖2 的顏色來匹配圖1，也就是用 im 除以 im 的高斯模糊，然後乘以 bg 的高斯模糊\n",
    "COLOUR_CORRECT_BLUR_FRAC = 0.8 #0.6\n",
    "LEFT_EYE_POINTS = list(range(42, 48))\n",
    "RIGHT_EYE_POINTS = list(range(36, 42))\n",
    "\n",
    "def correct_colours(bg, im, landmarks1):\n",
    "    blur_amount = COLOUR_CORRECT_BLUR_FRAC * np.linalg.norm(\n",
    "                             np.mean(landmarks1[LEFT_EYE_POINTS], axis=0) -\n",
    "                             np.mean(landmarks1[RIGHT_EYE_POINTS], axis=0))\n",
    "    blur_amount = int(blur_amount)\n",
    "    if blur_amount % 2 == 0:\n",
    "        blur_amount += 1\n",
    "    bg_blur = cv2.GaussianBlur(bg, (blur_amount, blur_amount), 0)\n",
    "    im_blur = cv2.GaussianBlur(im, (blur_amount, blur_amount), 0)\n",
    "\n",
    "    return (im.astype(np.float64) * bg_blur.astype(np.float64) / im_blur.astype(np.float64))\n",
    "\n",
    "\n",
    "#將圖2 的特徵融合到圖1 中\n",
    "LEFT_EYE_POINTS = list(range(42, 48))\n",
    "RIGHT_EYE_POINTS = list(range(36, 42))\n",
    "LEFT_BROW_POINTS = list(range(22, 27))\n",
    "RIGHT_BROW_POINTS = list(range(17, 22))\n",
    "NOSE_POINTS = list(range(27, 35))\n",
    "MOUTH_POINTS = list(range(48, 61))\n",
    "OVERLAY_POINTS = [\n",
    "   LEFT_EYE_POINTS + RIGHT_EYE_POINTS + LEFT_BROW_POINTS + RIGHT_BROW_POINTS,\n",
    "   NOSE_POINTS + MOUTH_POINTS,\n",
    "]\n",
    "FEATHER_AMOUNT = 11\n",
    "\n",
    "def draw_convex_hull(im, points, color):\n",
    "    points = cv2.convexHull(points)\n",
    "    cv2.fillConvexPoly(im, points, color=color)\n",
    "\n",
    "def get_face_mask(im, landmarks):\n",
    "    im = np.zeros(im.shape[:2], dtype=np.float64)\n",
    "\n",
    "    for group in OVERLAY_POINTS:\n",
    "        draw_convex_hull(im,\n",
    "                        landmarks[group],\n",
    "                        color=1)\n",
    "    im = np.array([im, im, im]).transpose((1, 2, 0))\n",
    "\n",
    "    im = (cv2.GaussianBlur(im, (FEATHER_AMOUNT, FEATHER_AMOUNT), 0) > 0) * 1.0\n",
    "    im = cv2.GaussianBlur(im, (FEATHER_AMOUNT, FEATHER_AMOUNT), 0)\n",
    "\n",
    "    return im\n",
    "\n",
    "\n",
    "def combine(bg_im, input_im, gender):\n",
    "    bg_points = bg_landmarks = get_landmarks(bg_im)\n",
    "    input_points = input_landmarks = get_landmarks(input_im)\n",
    "\n",
    "    M,R = transformation_from_points(bg_points, input_points)\n",
    "    mask = get_face_mask(input_im, input_landmarks)\n",
    "    warped_mask = warp_im(mask, M, bg_im.shape) \n",
    "    combined_mask = np.max([get_face_mask(bg_im, bg_landmarks), warped_mask], axis=0)\n",
    "    warped_im = warp_im(input_im,M, bg_im.shape)\n",
    "    warped_corrected_im = correct_colours(bg_im, warped_im, bg_landmarks)\n",
    "\n",
    "    #res_face = bg_im * (1.0 - combined_mask) + warped_corrected_im * combined_mask\n",
    "    cv2.imwrite(f\"mask_{gender}.jpeg\",warped_corrected_im * combined_mask)\n",
    "    a = cv2.imread(f\"mask_{gender}.jpeg\")\n",
    "    res_face = bg_im * (1.0 - combined_mask) + a\n",
    "    \n",
    "    os.remove(f\"mask_{gender}.jpeg\")\n",
    "\n",
    "    return res_face\n",
    "\n",
    "\n",
    "def fix(im,res_face,status):\n",
    "    faces = detector(im, 1)\n",
    "\n",
    "    for i in range(len(faces)):\n",
    "        x1 = faces[i].left()\n",
    "        y1 = faces[i].top()\n",
    "        x2 = faces[i].right()\n",
    "        y2 = faces[i].bottom()\n",
    "        \n",
    "        if status == True:\n",
    "            im[y1-50:y2+50, x1-50:x2+50] = res_face[i]\n",
    "        else:\n",
    "            im[y1-50:y2+50, x1-50:x2+50] = res_face[i-1]\n",
    "\n",
    "    return im\n",
    "\n",
    "\n",
    "def set_side_manR(left, cut):\n",
    "    if left[0] < left[1]:       \n",
    "        bg_f_im = cut[0]\n",
    "        bg_m_im = cut[1]\n",
    "        return True, bg_m_im , bg_f_im\n",
    "    else:                       \n",
    "        bg_m_im = cut[0]\n",
    "        bg_f_im = cut[1]\n",
    "        return False, bg_m_im , bg_f_im\n",
    "\n",
    "def set_side_manL(left, cut):\n",
    "    if left[0] < left[1]:       \n",
    "        bg_f_im = cut[1]\n",
    "        bg_m_im = cut[0]\n",
    "        return True, bg_m_im , bg_f_im\n",
    "    else:                       \n",
    "        bg_m_im = cut[1]\n",
    "        bg_f_im = cut[0]\n",
    "        return False, bg_m_im , bg_f_im    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "res_list1 = []\n",
    "for bg_or in bg_or_list1:\n",
    "    \n",
    "    bg_cut, bg_left,_ = cut(bg_or)\n",
    "    side_status, bg_m_im , bg_f_im = set_side_manR(bg_left, bg_cut)\n",
    "    size = max(bg_f_im.shape ,bg_m_im.shape)\n",
    "    f_im = cv2.resize(cut(f_im_or)[2], (size[1], size[0]))\n",
    "    m_im = cv2.resize(cut(m_im_or)[2], (size[1], size[0]))\n",
    "\n",
    "    result_face = []\n",
    "    result_face.append(combine(bg_f_im, f_im,'f'))\n",
    "    result_face.append(combine(bg_m_im, m_im,'m'))\n",
    "\n",
    "    result_im = fix(bg_or, result_face, side_status)\n",
    "    res_list1.append(result_im)\n",
    "    \n",
    "\n",
    "res_list2 = []\n",
    "for bg_or in bg_or_list2:\n",
    "    \n",
    "    bg_cut, bg_left,_ = cut(bg_or)\n",
    "    side_status, bg_m_im , bg_f_im = set_side_manL(bg_left, bg_cut)\n",
    "    size = max(bg_f_im.shape ,bg_m_im.shape)\n",
    "    f_im = cv2.resize(cut(f_im_or)[2], (size[1], size[0]))\n",
    "    m_im = cv2.resize(cut(m_im_or)[2], (size[1], size[0]))\n",
    "\n",
    "    result_face = []\n",
    "    result_face.append(combine(bg_m_im, m_im,'m'))\n",
    "    result_face.append(combine(bg_f_im, f_im,'f'))\n",
    "\n",
    "    result_im = fix(bg_or, result_face, side_status)\n",
    "    res_list2.append(result_im)    \n",
    "    \n",
    "\n",
    "    \n",
    "for i in range(len(res_list1)):\n",
    "    cv2.imwrite(f'./result/R_{i}.jpeg',res_list1[i])\n",
    "    \n",
    "for i in range(len(res_list2)):\n",
    "    cv2.imwrite(f'./result/L_{i}.jpeg',res_list2[i])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
